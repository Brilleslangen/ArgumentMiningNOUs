{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from models.Finetuner import FineTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a67edecb8e4482a7ea340e58c9093a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3048 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1116626f1ba146efac69fa810593265a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2743 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa3ef3f7dcd4e0eb654c3a51fd00087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/henrik/anaconda3/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "finetuner = FineTuner(model_name=\"TDT4310-NLP/nou_classifier_raw\",\n",
    "                      csv_path=\"../../dataset/nou_hearings.csv\",\n",
    "                      output_name=\"hello\",\n",
    "                      num_epochs=5,\n",
    "                      metric_names=('accuracy', 'recall', 'precision', 'f1'),\n",
    "                      wand_logging=False,\n",
    "                      eval_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id2label = finetuner.id2label\n",
    "#model_path = \"../../classifiers/Raw-Classifier\"\n",
    "#finetuner.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Privatperson'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "\n",
    "predictions = finetuner.predict(\"Det vises til høringsbrev av 31. oktober fra Klima- og miljødepartementet med høringsfrist 28. februar 2024.\")\n",
    "predictions = Tensor.cpu(predictions)\n",
    "prediction = np.argmax(predictions, axis=1)\n",
    "\n",
    "id2label[int(prediction[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 305\n",
      "})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/henrik/ArgumentMiningNOUs/src/notebooks/inference_bert.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/henrik/ArgumentMiningNOUs/src/notebooks/inference_bert.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m finetuner\u001b[39m.\u001b[39;49mevaluate()\n",
      "File \u001b[0;32m~/ArgumentMiningNOUs/src/notebooks/../models/Finetuner.py:182\u001b[0m, in \u001b[0;36mFineTuner.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    181\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mevaluate()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py:3365\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3362\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   3364\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3365\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   3366\u001b[0m     eval_dataloader,\n\u001b[1;32m   3367\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   3368\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3369\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3370\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   3371\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   3372\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   3373\u001b[0m )\n\u001b[1;32m   3375\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   3376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py:3576\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3570\u001b[0m     inputs_host \u001b[39m=\u001b[39m (\n\u001b[1;32m   3571\u001b[0m         inputs_decode\n\u001b[1;32m   3572\u001b[0m         \u001b[39mif\u001b[39;00m inputs_host \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3573\u001b[0m         \u001b[39melse\u001b[39;00m nested_concat(inputs_host, inputs_decode, padding_index\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m   3574\u001b[0m     )\n\u001b[1;32m   3575\u001b[0m \u001b[39mif\u001b[39;00m logits \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 3576\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mpad_across_processes(logits, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, pad_index\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m   3577\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_logits_for_metrics \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3578\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/accelerator.py:2350\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2317\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpad_across_processes\u001b[39m(\u001b[39mself\u001b[39m, tensor, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pad_index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pad_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   2318\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2319\u001b[0m \u001b[39m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2320\u001b[0m \u001b[39m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2348\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[1;32m   2349\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2350\u001b[0m     \u001b[39mreturn\u001b[39;00m pad_across_processes(tensor, dim\u001b[39m=\u001b[39;49mdim, pad_index\u001b[39m=\u001b[39;49mpad_index, pad_first\u001b[39m=\u001b[39;49mpad_first)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/utils/operations.py:417\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    416\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 417\u001b[0m         \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    418\u001b[0m     \u001b[39mexcept\u001b[39;00m DistributedOperationException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    419\u001b[0m         operation \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunction\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mfunction\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/utils/operations.py:684\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    681\u001b[0m     new_tensor[indices] \u001b[39m=\u001b[39m tensor\n\u001b[1;32m    682\u001b[0m     \u001b[39mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 684\u001b[0m \u001b[39mreturn\u001b[39;00m recursively_apply(\n\u001b[1;32m    685\u001b[0m     _pad_across_processes, tensor, error_on_other_type\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, dim\u001b[39m=\u001b[39;49mdim, pad_index\u001b[39m=\u001b[39;49mpad_index, pad_first\u001b[39m=\u001b[39;49mpad_first\n\u001b[1;32m    686\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/utils/operations.py:126\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[39melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m func(data, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    127\u001b[0m \u001b[39melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported types (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) passed to `\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m`. Only nested list/tuple/dicts of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobjects that are valid for `\u001b[39m\u001b[39m{\u001b[39;00mtest_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` should be passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/utils/operations.py:664\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n\u001b[1;32m    663\u001b[0m \u001b[39m# Gather all sizes\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m size \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(tensor\u001b[39m.\u001b[39;49mshape, device\u001b[39m=\u001b[39;49mtensor\u001b[39m.\u001b[39;49mdevice)[\u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    665\u001b[0m sizes \u001b[39m=\u001b[39m gather(size)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    666\u001b[0m \u001b[39m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "finetuner.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

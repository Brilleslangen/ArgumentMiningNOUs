




















































































































 29%|██▉       | 500/1715 [04:04<09:44,  2.08it/s]
 13%|█▎        | 5/39 [00:00<00:03,  8.71it/s]



 29%|██▉       | 500/1715 [04:11<09:44,  2.08it/s]
                                               00/4.20k [00:00<?, ?B/s]
{'eval_loss': 0.8729476928710938, 'eval_accuracy': 0.7114754098360656, 'eval_runtime': 7.8833, 'eval_samples_per_second': 38.689, 'eval_steps_per_second': 4.947, 'epoch': 1.46}



 97%|█████████▋| 38/39 [00:04<00:00,  8.48it/s]00/4.20k [00:00<?, ?B/s]

                                               00/4.20k [00:00<?, ?B/s]




                                               00/4.20k [00:00<?, ?B/s]
  File "/Users/nicolaisivesind/Desktop/Datateknologi/NLP/Project/ArgumentMiningNOUs/src/models/Finetuner.py", line 114, in <module>
    finetuner.train()
  File "/Users/nicolaisivesind/Desktop/Datateknologi/NLP/Project/ArgumentMiningNOUs/src/models/Finetuner.py", line 106, in train
    self.trainer.train()
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py", line 1780, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/utils/memory.py", line 142, in decorator
    return function(batch_size, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py", line 2118, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py", line 3045, in training_step
    self.accelerator.backward(loss)
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/accelerator.py", line 2013, in backward
    loss.backward(**kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
